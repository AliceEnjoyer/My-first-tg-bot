package eventConsumer

import (
	"firstTGBot/events"
	"log"
	"time"
)

type EventsConsumer struct {
	fetcher   events.Fetcher
	processor events.Processor
	batchSize int // размер пачки (сколько сообщений будет обрабатыватся за раз)
}

func New(fetcher events.Fetcher, processor events.Processor, batchSize int) EventsConsumer {
	return EventsConsumer{
		fetcher:   fetcher,
		processor: processor,
		batchSize: batchSize,
	}
}

func (c *EventsConsumer) Start() error {
	for {
		gotEvents, err := c.fetcher.Fetch(c.batchSize)

		/*
			Такой обработчик не очень хороший,
			Почему эта ошибка может случатся? Например у нас могла быть временная проблема с сетью,
			то есть мы с помощью фэтчера не достучались до какого-то сервиса и в результатах, в рамках данной итерации, не
			смогли получить новую пачку для обработки и в таком случае мы пропускаем итерацию и ждем новой. В этом случем
			это не очень большая проблема, так как у нас итерации раз в секунду, но если будет обработка раз в час, то из-за
			какой-то небольшой ошибки из сетью нужно будет ждать целый час. Так же перед блоком обработки ошибки могли идти какие-то действия,
			которые моглы быть даже очень объемными, и их тогда придется выполнять заново.

			В текущий фэтчер можно встроить механизм retry, то есть если не получилось получить данные за один раз,
			то мы пробуем сделать это еще раз. Можно сделать 3 попытки в промежутке одной секунды, но можно так же сделать
			несколько попыток (или до временни некоторого таймаута) с экспоненциальными растущими промежутками,
			то есть 1 сек -> 2 сек -> 4 сек и так далее.
		*/
		if err != nil {
			log.Printf("[ERR] EventsConsumer: %s", err.Error())

			continue
		}

		if len(gotEvents) == 0 {
			time.Sleep(1 * time.Second)
			continue
		}
		if err := c.handleEvents(gotEvents); err != nil {
			log.Print(err)
			continue
		}
	}
}

func (c *EventsConsumer) handleEvents(events []events.Event) error {
	for _, ev := range events {
		log.Printf("got new event: %s", ev.Text)

		/*
			Что потенциально может быть не так с этой логикой?
			Мы можем потерять то, что не обработали. Фэтчер уже нам дал эту пачку событий и сделал сдвиг (offset),
			то есть след раз он нам выдаст новую пачку и ,просто пропуская обработку события, мы теряем его навсегда.
			Мы так же можем добавить механизм retry, кроме того, мы можем добвать механизм бэкапа (добавляем не обработаные
			ссылки в бэкап, что бы потом обработать, но тоже может не работать из-за возможных изначальных проблем из сетью).
			След проблема заключается в том, что мы можем пытатся обработать каждый из этих событий, даже в том случае если у каждошо из
			них будет ошибка (если обвалилась сеть, то ни одно событие не обработается и если установлены длинные таймауты ,к примеру в несколько секунд,
			то обработка большой пачки займет очень много времени). Исправить можно так - вместо continue сразу возвращаем ошибку и прекращаем обработку
			текущей пачки, или же делаем некий счетчик и ,при достижении некторого числа ошибок подряд, мы также возвращаем ошибку.

			Так же можно выполнить эту всю обработку событий асинхронно.

			Итог решений:
			1. Потеря событий: ретраи, возвращение в хранилище, фоллбэк, подтверждениие для фэтчера, что мы все обработали.
			2. Обработка всей пачки: останавливать после первой же ошибки, сделать счетчик.
			3. Паралельная обработка. (WaitGroup)
		*/
		if err := c.processor.Process(ev); err != nil {
			log.Printf("can not handle events: %s", err.Error())
			continue
		}
	}
	return nil
}
